{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a network\n",
    "\n",
    "Let's take a detailed look at how we train a new deep learning model from pre-prepared data with dtoolAI. We're going to train a convolutional neural network (CNN) to recognise handwritten digits from the MNIST dataset.\n",
    "\n",
    "## Loading our data\n",
    "\n",
    "First, we'll need to load our data, using the appropriate class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dtoolai.data import TensorDataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now load our data from a persistent identifier (URI):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_uri = \"http://bit.ly/2uqXxrk\"\n",
    "train_ds = TensorDataSet(train_dataset_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at what we've loaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "data, label = train_ds[9000]\n",
    "print(data.shape)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data are 1x28x28 arrays representing digits. We can load a helper function to visualise them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dtoolai.data import scaled_float_array_to_pil_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then visualise a single digit like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAfElEQVR4nGNgGOQgfz9uObVXf5B4TKiSlkK3cEt6MWzFLcnIyIhb8v9/3DrFHRl4cTpW9s81fpw6CxgvfcRjJwoPVTKC4RYDTvD3jwVunUyMDLjB32vCOHWqMbx7i1NSkuEsA05JYyYT3JJb/uHxJx5PMjAwfLTGK00lAADhVhsa1EL81AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x11426AE10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_float_array_to_pil_image(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting parameters\n",
    "\n",
    "Next we'll set some parameters with which to train our model. We'll use dtoolAI's Parameters class for this, since we'll then be able to record those parameters during training automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dtoolai.parameters import Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Parameters(\n",
    "    batch_size=128,\n",
    "    learning_rate=0.01,\n",
    "    n_epochs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model, optimiser, loss function\n",
    "\n",
    "In general, to train a deep learning model we need three things:\n",
    "\n",
    "1. A suitable model architecture.\n",
    "2. A loss function (how the difference between target labels and predicted labels will be calculated).\n",
    "3. Training data.\n",
    "\n",
    "We've loaded the data, now we need the model and a loss function. We'll also need to choose an optimiser.\n",
    "\n",
    "Firstly, we'll load our generic classifier model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dtoolai.models import GenNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then we can set the model's parameters from what we know about the dataset and initialise it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['init_params'] = dict(input_channels=train_ds.input_channels, input_dim=train_ds.dim)\n",
    "model = GenNet(**params['init_params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create a loss function and optimiser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "loss_fn = torch.nn.NLLLoss()\n",
    "optim = torch.optim.SGD(model.parameters(), lr=params.learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Now we're ready to train our model. First we import a helper function from dtoolAI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dtoolai.training import train_model_with_metadata_capture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and another function to make sure our new model is packaged with useful metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dtoolcore import DerivedDataSetCreator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cpu\n",
      "  Epoch 0, batch 0/469, running loss 2.306\n",
      "  Epoch 0, batch 10/469, running loss 25.385\n",
      "  Epoch 0, batch 20/469, running loss 48.437\n",
      "  Epoch 0, batch 30/469, running loss 71.473\n",
      "  Epoch 0, batch 40/469, running loss 94.530\n",
      "  Epoch 0, batch 50/469, running loss 117.592\n",
      "  Epoch 0, batch 60/469, running loss 140.637\n",
      "  Epoch 0, batch 70/469, running loss 163.678\n",
      "  Epoch 0, batch 80/469, running loss 186.687\n",
      "  Epoch 0, batch 90/469, running loss 209.687\n",
      "  Epoch 0, batch 100/469, running loss 232.699\n",
      "  Epoch 0, batch 110/469, running loss 255.694\n",
      "  Epoch 0, batch 120/469, running loss 278.677\n",
      "  Epoch 0, batch 130/469, running loss 301.655\n",
      "  Epoch 0, batch 140/469, running loss 324.613\n",
      "  Epoch 0, batch 150/469, running loss 347.553\n",
      "  Epoch 0, batch 160/469, running loss 370.473\n",
      "  Epoch 0, batch 170/469, running loss 393.384\n",
      "  Epoch 0, batch 180/469, running loss 416.292\n",
      "  Epoch 0, batch 190/469, running loss 439.195\n",
      "  Epoch 0, batch 200/469, running loss 462.075\n",
      "  Epoch 0, batch 210/469, running loss 484.933\n",
      "  Epoch 0, batch 220/469, running loss 507.774\n",
      "  Epoch 0, batch 230/469, running loss 530.613\n",
      "  Epoch 0, batch 240/469, running loss 553.446\n",
      "  Epoch 0, batch 250/469, running loss 576.257\n",
      "  Epoch 0, batch 260/469, running loss 599.045\n",
      "  Epoch 0, batch 270/469, running loss 621.803\n",
      "  Epoch 0, batch 280/469, running loss 644.548\n",
      "  Epoch 0, batch 290/469, running loss 667.244\n",
      "  Epoch 0, batch 300/469, running loss 689.926\n",
      "  Epoch 0, batch 310/469, running loss 712.568\n",
      "  Epoch 0, batch 320/469, running loss 735.184\n",
      "  Epoch 0, batch 330/469, running loss 757.763\n",
      "  Epoch 0, batch 340/469, running loss 780.265\n",
      "  Epoch 0, batch 350/469, running loss 802.731\n",
      "  Epoch 0, batch 360/469, running loss 825.148\n",
      "  Epoch 0, batch 370/469, running loss 847.488\n",
      "  Epoch 0, batch 380/469, running loss 869.745\n",
      "  Epoch 0, batch 390/469, running loss 891.937\n",
      "  Epoch 0, batch 400/469, running loss 913.997\n",
      "  Epoch 0, batch 410/469, running loss 935.965\n",
      "  Epoch 0, batch 420/469, running loss 957.786\n",
      "  Epoch 0, batch 430/469, running loss 979.436\n",
      "  Epoch 0, batch 440/469, running loss 1000.971\n",
      "  Epoch 0, batch 450/469, running loss 1022.304\n",
      "  Epoch 0, batch 460/469, running loss 1043.377\n",
      "Epoch 0, training loss 1059.980, time 14.96s\n"
     ]
    }
   ],
   "source": [
    "with DerivedDataSetCreator('mnist.example.model', '../scratch', train_ds) as output_ds:\n",
    "    train_model_with_metadata_capture(model, train_ds, optim, loss_fn, params, output_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model\n",
    "\n",
    "The MNIST dataset actually contains 60,000 training examples (which we used to train our model), and 10,000 test examples. We can use this latter set of examples to test our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_test_uri = \"http://bit.ly/2NVFGQd\"\n",
    "test_ds = TensorDataSet(mnist_test_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = DataLoader(test_ds, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dtoolai.utils import evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = evaluate_model(model, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9542"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking model provenance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dtoolai.trained import TrainedTorchModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttm = TrainedTorchModel(\"../scratch/mnist.example.model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://bit.ly/2uqXxrk'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttm.dataset.get_annotation(\"source_dataset_uri\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dtoolcore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dataset = dtoolcore.DataSet.from_uri('http://bit.ly/2uqXxrk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "dataset_name: MNIST handwritten digits\n",
      "project: dtoolAI demonstration datasets\n",
      "authors:\n",
      "  - Yann LeCun\n",
      "  - Corinna Cortes\n",
      "  - Christopher J.C. Burges\n",
      "origin: http://yann.lecun.com/exdb/mnist/\n",
      "usetype: train\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(source_dataset.get_readme_content())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
